{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking1\tXGBoost与GBDT的区别是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost是GBDT在工程上的优化。传统GBDT以CART作为基分类器，xgboost还支持线性分类器；传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数；xgboost在代价函数里加入了正则项，用于控制模型的复杂度。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking2\t举一个你之前做过的预测例子\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我用LR模型，对员工离职进行了预测。首先将数据导入后使用head()和info()来查看数据的详细信息，对数据有一个大概的了解。将标签和数据集分开，再将数据集按照7：3的比例分为训练集和测试集，对类别型特征进行DictVectorizer向量化，对数值型特征进行标准化。然后分别使用了决策树、随机森林和逻辑回归来进行训练，其准确率分别为0.782312925170068、0.8741496598639455、0.8877551020408163，最后选择了逻辑回归。使用训练好的逻辑回归模型对测试集进行预测，最后的预测准确率是0.82418。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking3\t请你思考，在你的工作中，需要构建哪些特征（比如用户画像，item特征...），这些特征都包括哪些维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "item一般是指一个需要打分的个体，搜索中，是等待被搜索的个体；推荐中，是等待被推荐的个体。在item中，主要会用到item的类别和item的统计类特征，在统计类特征中，不是只有sum，ratio，average等这样的特征，有时候会用到平滑因子。例如A广告投放了10次，被点击1次，B广告投放了1000次，被点击了10次，我们并不能说A的ctr是0.1，因为这样会带来很大的偶然性，此时我们可以加入平滑因子。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
